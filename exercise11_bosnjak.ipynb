{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde62628-911f-4c38-8297-c60b795115f0",
   "metadata": {},
   "source": [
    "# Exercise sheet 11 - Parallelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f316e46-c426-461e-82e4-dc385cfca0f9",
   "metadata": {},
   "source": [
    "# Exercise 1 - Rigged dice\n",
    "\n",
    "Create a rigged dice function that 25% of the time returns the number 6. The rest of the time it returns the integers 1,2,3,4,5 uniformly.\n",
    "Test your function, by calling it **one billion times** (10^9) and checking that 6 is returned in the range of 249-251 million (inclusive) times. You do not need to check that numbers 1 to 5 are returned uniformly or randomly, but you need to check that your function returns integers in the range 1-6 (inclusive). **Time** how long it takes to run the script.\n",
    "\n",
    "Now attempt to **parallelise the task with a method of your own choosing** and time how long it takes once more. How does this compare to the previous *un-optimised* run?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdccabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rigged_dice():\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    sum3 = 0\n",
    "    sum4 = 0\n",
    "    sum5 = 0\n",
    "    sum6 = 0\n",
    "    for i in range(10**6):      #generate dice\n",
    "        numbers = random.choice([1, 2, 3, 4, 5, 6], p=[0.15, 0.15, 0.15, 0.15, 0.15, 0.25])\n",
    "        if numbers == 1:\n",
    "            sum1 += 1\n",
    "        elif numbers == 2:\n",
    "            sum2 += 1\n",
    "        elif numbers == 3:\n",
    "            sum3 += 1\n",
    "        elif numbers == 4:\n",
    "            sum4 += 1\n",
    "        elif numbers == 5:\n",
    "            sum5 += 1\n",
    "        elif numbers == 6:\n",
    "            sum6 += 1\n",
    "    print(sum1)\n",
    "    print(sum2)\n",
    "    print(sum3)\n",
    "    print(sum4)\n",
    "    print(sum5)\n",
    "    print(sum6)\n",
    "\n",
    "#time how long it takes to run the script\n",
    "execution_time = timeit.timeit(rigged_dice, number=1)\n",
    "print(f\"execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rigged_dice(task_id): #the task_id is kinda like a dummy argument\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    sum3 = 0\n",
    "    sum4 = 0\n",
    "    sum5 = 0\n",
    "    sum6 = 0\n",
    "    for i in range(10**6 // 4): #divide the amount of iterations by 4, so that each process runs 1/4 of the iterations\n",
    "        numbers = random.choice([1, 2, 3, 4, 5, 6], p=[0.15, 0.15, 0.15, 0.15, 0.15, 0.25])\n",
    "        if numbers == 1:\n",
    "            sum1 += 1\n",
    "        elif numbers == 2:\n",
    "            sum2 += 1\n",
    "        elif numbers == 3:\n",
    "            sum3 += 1\n",
    "        elif numbers == 4:\n",
    "            sum4 += 1\n",
    "        elif numbers == 5:\n",
    "            sum5 += 1\n",
    "        elif numbers == 6:\n",
    "            sum6 += 1\n",
    "    return [sum1, sum2, sum3, sum4, sum5, sum6] #return the results as a list since i now have a function\n",
    "\n",
    "\n",
    "def rigged_dice_parallel(rigged_dice_fn):\n",
    "    with multiprocessing.Pool(4) as pool:  #creating a pool of 4 processes\n",
    "        results = pool.map(rigged_dice_fn, range(4)) #mapping the function to the pool of processes\n",
    "        #combining results from all processes\n",
    "        final_counts = [sum(result[i] for result in results) for i in range(6)]\n",
    "        print(final_counts)\n",
    "\n",
    "#execution time of the parallel code\n",
    "execution_time_parallel = timeit.timeit(lambda: rigged_dice_parallel(rigged_dice), number=1)\n",
    "print(f\"Execution time parallel: {execution_time_parallel:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5547c0f3",
   "metadata": {},
   "source": [
    "# Exercise 2 - Calculate $\\pi$\n",
    "\n",
    "Using the **DSMC method**, calculate the value of **$\\pi$**.\n",
    "\n",
    "\n",
    "**Approach:**\n",
    "In order to do this, create a 2-dimensional domain (defined by the coordinates $x_{min}, x_{max}, y_{min}, y_{max}$) and launch a number P of particles at random locations within. Check which particles lie inside a circle with radius $$ \\frac{x_{max}-x_{min}}{2}, $$ where $x_{min}, x_{max}$ are the x-limits of your 2D domain. \n",
    "\n",
    "Get your value for $\\pi$ by using the following formula:\n",
    "$\\pi = \\frac{4 \\cdot n_{inside}}{P},$ where $n_{inside}$ is the number of particles inside the circle and $P$ is the total number of particles.\n",
    "\n",
    "Play around with the number of particles. \n",
    "\n",
    "**a)** Try to improve this task by making use of threading (you can use either the **_thread** or **threading** module). What are your findings, is the script running faster? \n",
    "\n",
    "**b)** Now try to improve the running time of the code by employing the **multiprocessing** module. Are there any differences as compared to threading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eab9292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi estimate: 3.1415196\n",
      "Time: 2.78 s\n",
      "Pi estimate (threaded): 3.141432\n",
      "Time: 2.64 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-2:\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m P \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10_000_000\u001b[39m\n\u001b[1;32m     79\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 80\u001b[0m pi_est \u001b[38;5;241m=\u001b[39m estimate_pi_multiprocessing(P, n_processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     81\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPi estimate (multiprocessing): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpi_est\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 72\u001b[0m, in \u001b[0;36mestimate_pi_multiprocessing\u001b[0;34m(P, n_processes)\u001b[0m\n\u001b[1;32m     69\u001b[0m P_per_proc \u001b[38;5;241m=\u001b[39m P \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_processes\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mn_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 72\u001b[0m     results \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap(worker, [P_per_proc] \u001b[38;5;241m*\u001b[39m n_processes)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(results) \u001b[38;5;241m/\u001b[39m P\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, mapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def estimate_pi(P):\n",
    "    inside = 0\n",
    "    for _ in range(P):      #loop randomly chooses a point within square [-1, 1] [-1,1] \n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        if x*x + y*y <= 1:\n",
    "            inside += 1\n",
    "    return 4 * inside / P   #formula given in assignment (circle area / square area = pi/4)\n",
    "\n",
    "P = 10_000_000\n",
    "\n",
    "start = time.time()         #time package counts time for me\n",
    "pi_est = estimate_pi(P)     #value of pi estimate\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Pi estimate: {pi_est}\")\n",
    "print(f\"Time: {end - start:.2f} s\")\n",
    "\n",
    "\n",
    "\n",
    "def thread(P, results, idx):\n",
    "    inside = 0\n",
    "    for _ in range(P):\n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        if x*x + y*y <= 1:\n",
    "            inside += 1\n",
    "    results[idx] = inside       #saves each thread in an index\n",
    "\n",
    "def estimate_pi_threaded(P, n_threads=4):   #amount of threads \n",
    "    threads = []\n",
    "    results = [0] * n_threads\n",
    "    P_per_thread = P // n_threads\n",
    "\n",
    "    for i in range(n_threads):\n",
    "        t = threading.Thread(target=thread, args=(P_per_thread, results, i))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    return 4 * sum(results) / P             #formula given in assignment adjusted to sum the results of x threads \n",
    "\n",
    "\n",
    "start = time.time()\n",
    "pi_est = estimate_pi_threaded(P, n_threads=4)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Pi estimate (threaded): {pi_est}\")\n",
    "print(f\"Time: {end - start:.2f} s\")\n",
    "\n",
    "\n",
    "\n",
    "def mproc(P):\n",
    "    inside = 0\n",
    "    for _ in range(P):                      #loop randomly chooses a point within square [-1, 1] [-1,1] \n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        if x*x + y*y <= 1:                  #check if point is within our square\n",
    "            inside += 1\n",
    "    return inside\n",
    "\n",
    "def estimate_pi_multiprocessing(P, n_processes=4):\n",
    "    P_per_proc = P // n_processes           #splits work by amount of processes defined above\n",
    "\n",
    "    with mp.Pool(processes=n_processes) as pool:                    #creates as many 'workers' as there are procs\n",
    "        results = pool.map(mproc, [P_per_proc] * n_processes)       #calls mproc(P) for each process and saves it\n",
    "\n",
    "    return 4 * sum(results) / P             #formula given in assignment adjusted to sum the results of x processes \n",
    "\n",
    "if __name__ == \"__main__\":                  #code only runs when the file is executed directly\n",
    "    P = 10_000_000\n",
    "\n",
    "    start = time.time()                                         #time package counts time for me\n",
    "    pi_est = estimate_pi_multiprocessing(P, n_processes=4)      #value of pi estimate\n",
    "    end = time.time()                                           \n",
    "\n",
    "    print(f\"Pi estimate (multiprocessing): {pi_est}\")\n",
    "    print(f\"Time: {end - start:.2f} s\")\n",
    "\n",
    "    #threaded averages about 3s\n",
    "    #multiprocessing averages about 7s\n",
    "    #multiprocessing is inefficient on mac? uses 'spawn' compared to 'fork' on linux\n",
    "    #spawn re-imports all our modules which takes time\n",
    "    #P and amount of processes might be too light as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe04167-4133-46d8-bd93-796b45f0fd1f",
   "metadata": {},
   "source": [
    "# Exercise 3 - Mandelbrot fractals\n",
    "\n",
    "Read about the Mandelbrot set: https://en.wikipedia.org/wiki/Mandelbrot_set. \n",
    "This set is defined by repeatedly applying this recurrence:\n",
    "\n",
    "$z_{n+1} = z_{n}^2 + c$,\n",
    "\n",
    "which starts with $z_{0} = 0$ for a given complex number $c$ (each pixel corresponds to one $c$). The idea is to check if a particle \"escapes\" at a certain iteration. At each iteration, one checks if the sequence $z_0, z_1, ... z_n$ growing or stays bound. The growing condition: $|z_n| > 2$. If the condition ```if (z.real*z.real + z.imag*z.imag) > 4``` is fulfilled at any step, we mark the particle as \"escaped\". If the sequence stays bound forever (never uncontrollably grows for a given number of iterations, for instance, 300), then it is inside the the Mandelbrot set.\n",
    "\n",
    "**(A)** Create a script which visualizes the Mandelbrot set. The X-axis is the real part of the complex number, the Y-axis is the imaginary part. You can use the colorscheme of your choice. Mark the particles which never escape as one color, and color the escaped particles based on how fast they escaped (that is, use the iteration at which they escaped for your colorbar). You should define the width and height of your image (for instance, 1000 and 700, but you can change it if you like), and \n",
    "\n",
    "**(B)** Parallelize your Mandelbrot function using the *multiprocessing* module. Experiment with different sizes of datachunks you give separate processors (you can split the data by column chunks or row chunks and process them separately in separate processes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c38f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
